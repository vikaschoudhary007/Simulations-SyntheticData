{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "world = client.get_world()\n",
    "\n",
    "bp_lib = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_bp = bp_lib.find('vehicle.lincoln.mkz_2020')\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "\n",
    "spectator = world.get_spectator()\n",
    "vehicle_transform = vehicle.get_transform()\n",
    "transform = carla.Transform(vehicle_transform.location + carla.Location(x=-4, z=2.5),vehicle_transform.rotation)\n",
    "spectator.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "camera_init_trans = carla.Transform(carla.Location(z=2, x=0.4))\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "time.sleep(0.2)\n",
    "spectator.set_transform(camera.get_transform())\n",
    "# camera.destroy()\n",
    "\n",
    "# SAVE CAMERA IMAGES to out directory\n",
    "# camera.listen(lambda image: image.save_to_disk('out/%06d.png' % image.frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_callback(image, data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_w = camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "\n",
    "camera_data = {'image': np.zeros((image_h, image_w, 4))}\n",
    "\n",
    "camera.listen(lambda image: camera_callback(image, camera_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle.set_autopilot(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_415756/216754594.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB Camera'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cv2.namedWindow('RGB Camera', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('RGB Camera', camera_data['image'])\n",
    "cv2.waitKey(1)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('RGB Camera', camera_data['image'])\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor.other.lane_invasion\n",
      "sensor.other.collision\n",
      "sensor.camera.depth\n",
      "sensor.lidar.ray_cast\n",
      "sensor.camera.semantic_segmentation\n",
      "sensor.other.radar\n",
      "sensor.camera.instance_segmentation\n",
      "sensor.camera.rgb\n",
      "sensor.other.rss\n",
      "sensor.camera.optical_flow\n",
      "sensor.lidar.ray_cast_semantic\n",
      "sensor.other.obstacle\n",
      "sensor.other.imu\n",
      "sensor.other.gnss\n",
      "sensor.camera.dvs\n",
      "sensor.camera.normals\n"
     ]
    }
   ],
   "source": [
    "# different types of sensors available\n",
    "\n",
    "for bp in bp_lib.filter('sensor'):\n",
    "    print(bp.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in world.get_actors().filter('*vehicle*'):\n",
    "    v.set_autopilot(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the traffic in simulation\n",
    "\n",
    "camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "sem_camera_bp = bp_lib.find('sensor.camera.semantic_segmentation')\n",
    "sem_camera = world.spawn_actor(sem_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "inst_camera_bp = bp_lib.find('sensor.camera.instance_segmentation')\n",
    "inst_camera = world.spawn_actor(inst_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "depth_camera_bp = bp_lib.find('sensor.camera.depth')\n",
    "depth_camera = world.spawn_actor(depth_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "dvs_camera_bp = bp_lib.find('sensor.camera.dvs')\n",
    "dvs_camera = world.spawn_actor(dvs_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "opt_camera_bp = bp_lib.find('sensor.camera.optical_flow')\n",
    "opt_camera = world.spawn_actor(opt_camera_bp, camera_init_trans, attach_to=vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_callback(image, data_dict):\n",
    "    data_dict['rgb_image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "def sem_callback(image, data_dict):\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "def inst_callback(image, data_dict):\n",
    "    data_dict['inst_image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "def depth_callback(image, data_dict):\n",
    "    image.convert(carla.ColorConverter.LogarithmicDepth)\n",
    "    data_dict['depth_image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "def opt_callback(data, data_dict):\n",
    "    image = data.get_color_coded_flow()\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    img[:,:,3] = 255\n",
    "    data_dict['opt_image'] = img\n",
    "\n",
    "def dvs_callback(data, data_dict):\n",
    "    dvs_events = np.frombuffer(data.raw_data, dtype=np.dtype([\n",
    "        ('x', np.uint16), ('y', np.uint16), ('t', np.int64), ('pol', np.bool)]))\n",
    "    data_dict['dvs_image'] = np.zeros((data.height, data.width, 4), dtype=np.uint8)\n",
    "    dvs_img = np.zeros((data.height, data.width, 3), dtype=np.uint8)\n",
    "    dvs_img[dvs_events[:]['y'], dvs_events[:]['x'], dvs_events[:]['pol']*2] = 255\n",
    "    data_dict['dvs_image'][:,:,0:3] = dvs_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_554619/2329369923.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All Cameras'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_w = camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "\n",
    "sensor_data = {'rgb_image': np.zeros((image_h, image_w, 4)),\n",
    "               'sem_image': np.zeros((image_h, image_w, 4)),\n",
    "               'depth_image': np.zeros((image_h, image_w, 4)),\n",
    "               'dvs_image': np.zeros((image_h, image_w, 4)),\n",
    "               'opt_image': np.zeros((image_h, image_w, 4)),\n",
    "               'inst_image': np.zeros((image_h, image_w, 4))}\n",
    "\n",
    "cv2.namedWindow('All Cameras', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "top_row = np.concatenate((sensor_data['rgb_image'], sensor_data['sem_image'], sensor_data['inst_image']), axis=1)\n",
    "lower_row = np.concatenate((sensor_data['depth_image'], sensor_data['dvs_image'], sensor_data['opt_image']), axis=1)\n",
    "tiled = np.concatenate((top_row, lower_row), axis=0)\n",
    "\n",
    "cv2.imshow('All Cameras', tiled)\n",
    "cv2.waitKey(1)\n",
    "\n",
    "camera.listen(lambda image: rgb_callback(image, sensor_data))\n",
    "sem_camera.listen(lambda image: sem_callback(image, sensor_data))\n",
    "inst_camera.listen(lambda image: inst_callback(image, sensor_data))\n",
    "depth_camera.listen(lambda image: depth_callback(image, sensor_data))\n",
    "dvs_camera.listen(lambda image: dvs_callback(image, sensor_data))\n",
    "opt_camera.listen(lambda image: opt_callback(image, sensor_data))\n",
    "\n",
    "while True:\n",
    "\n",
    "    top_row = np.concatenate((sensor_data['rgb_image'], sensor_data['sem_image'], sensor_data['inst_image']), axis=1)\n",
    "    lower_row = np.concatenate((sensor_data['depth_image'], sensor_data['dvs_image'], sensor_data['opt_image']), axis=1)\n",
    "    tiled = np.concatenate((top_row, lower_row), axis=0)\n",
    "    \n",
    "    cv2.imshow('All Cameras', tiled)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "camera.stop()\n",
    "sem_camera.stop()\n",
    "inst_camera.stop()\n",
    "depth_camera.stop()\n",
    "dvs_camera.stop()\n",
    "opt_camera.stop()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "               "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
